# 未来方向（参考，暂不实现）

> 记录可能的发展方向，供未来决策参考
> 当前阶段：AI 纪要生成已可用，其他方向暂停

---

## 1. 模型演进规划

### 当前状态（2026-02-26）

| 组件 | 当前方案 | 说明 |
|------|----------|------|
| 转写引擎 | faster-whisper small | ~244MB，纯CPU，平衡方案 |
| AI纪要 | DeepSeek API | 云端调用，当前稳定 |

### 转写模型演进路线

```
Phase 1 (当前): faster-whisper small (CPU)
   ↓
Phase 2 (客户部署): faster-whisper large-v3 (GPU)
   ↓
Phase 3 (未来): 公司自研转写API
```

| 阶段 | 模型 | 大小 | 设备 | 适用场景 |
|------|------|------|------|----------|
| 当前 | small | 244MB | CPU | 临时部署（虚拟机无GPU） |
| 客户 | large-v3 | 1550MB | GPU | 客户服务器（有GPU） |
| 未来 | 公司API | - | 云端 | 接入公司自研能力 |

### AI纪要演进路线

```
Phase 1 (当前): DeepSeek API
   ↓
Phase 2 (Phase 4): 通义千问 API（可选）
   ↓
Phase 3 (未来): 公司自研大模型API
```

**接入方式**：
```bash
# 当前
AI_PROVIDER=deepseek
DEEPSEEK_API_KEY=xxx

# 未来（公司自研）
AI_PROVIDER=company
COMPANY_API_KEY=xxx
COMPANY_BASE_URL=https://api.your-company.com/v1
COMPANY_MODEL=company-chat
```

### 配置化方案

已在 `.env` 预留配置项：

```bash
# 转写配置
WHISPER_MODEL=small              # tiny/base/small/medium/large-v3
WHISPER_DEVICE=cpu               # cpu/cuda/auto
WHISPER_COMPUTE_TYPE=int8        # int8/float16/float32

# AI提供商
AI_PROVIDER=deepseek             # deepseek/tongyi/openai/company
```

---

## 2. 知识库打通（暂不实现）

### 场景
用户开完会，会议纪要自动进入"帮我存"知识库，可检索、可关联。

### 可能方案
| 方案 | 描述 | 复杂度 |
|------|------|--------|
| A. API 推送 | 知识库提供接口，主动推送 | 低 |
| B. 数据库共享 | 统一存储层 | 中 |
| C. 消息队列 | 异步同步 | 高 |

### 待确定
- [ ] 灵犀知识库接口规范
- [ ] 同步时机（实时/定时/手动）
- [ ] 冲突处理（重复会议）

**状态**：⏸️ 等灵犀接口稳定后再对接

---

## 3. 实时推送（暂不实现）

### 场景
会议进行中实时显示字幕、议题标记。

### 技术点
- WebSocket 服务端 → 前端推送协议
- 流式 AI 理解（增量提取议题）
- 延迟控制 < 3秒

**状态**：⏸️ 当前会后生成模式够用

---

## 4. 状态持久化（暂不实现）

### 场景
服务重启不丢数据，支持"当前谁在开会"。

### 技术点
- SQLite/Redis 存储会议状态
- 状态机（准备→录音→处理→完成）

**状态**：⏸️ 当前内存存储够用

---

## 三、迭代路线图

> 合并自 未来更新计划.md

### V1.0 基础闭环（已完成）
- [x] 音频转写（Whisper）
- [x] AI 纪要生成（DeepSeek）
- [x] 文件存储（JSON/DOCX）
- [x] 基础查询

### V1.5 稳定化（当前）
- [ ] 修 bug（超时处理、磁盘满等）
- [ ] 错误处理完善
- [ ] 关键日志补充
- [ ] 转写模型可配置化（small → large-v3）

### V2.0 实时增强（未来）
- [ ] WebSocket 实时推送
- [ ] 流式 AI 理解
- [ ] 会议状态持久化
- [ ] 接入公司自研API

### V3.0 生态扩展（未来）
- [ ] 知识库打通
- [ ] 用户权限隔离
- [ ] 多音频源支持

---

## 当前优先级

1. **P0**: 确保现有功能稳定
2. **P1**: 跑通完整业务流程
3. **P2**: 转写模型可配置化（支持客户GPU环境）
4. **P3**: Phase 4 AI纪要增强
5. **P4**: 知识库打通（等灵犀接口）
6. **P5**: 实时增强（以后再说）

---

*记录时间：2026-02-26*
*状态：模型规划已更新，文档已同步*
